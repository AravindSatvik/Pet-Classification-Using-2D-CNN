{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "communist-celebrity",
   "metadata": {},
   "source": [
    "# Importing the Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "brave-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator, load_img\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "graphic-beach",
   "metadata": {},
   "source": [
    "# Preparing the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "oriented-africa",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_filenames=os.listdir('./dataset/train')\n",
    "classes=[]\n",
    "for i in training_set_filenames:\n",
    "    pet_name=i.split('.')[0]\n",
    "    if pet_name=='dog':\n",
    "        classes.append('dog')\n",
    "    elif pet_name=='cat':\n",
    "        classes.append('cat')\n",
    "df=pd.DataFrame({\n",
    "    'file_name':training_set_filenames,\n",
    "    'class':classes\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "shared-chick",
   "metadata": {},
   "source": [
    "# Splitting the dataframe into training and validation dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sexual-preliminary",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 2)\n",
      "(5000, 2)\n"
     ]
    }
   ],
   "source": [
    "train_df,validation_df=train_test_split(df,test_size=0.2,random_state=40)\n",
    "train_df=train_df.reset_index(drop=True)\n",
    "validation_df=validation_df.reset_index(drop=True)\n",
    "print(train_df.shape)\n",
    "print(validation_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "floral-melissa",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "european-power",
   "metadata": {},
   "source": [
    "Preprocessing the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "varying-roller",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 20000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_data_gen=ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    zoom_range=0.2,\n",
    "    shear_range=0.1,\n",
    "    rotation_range=15,\n",
    "    horizontal_flip=True,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1)\n",
    "\"\"\"rescale is like feature scaling. In feature scaling, we reduce the values to a certain range. Here, rescale will reduce each \n",
    "pixel value by dividing with 255 so that pixel values range between 0 and 1\"\"\"\n",
    "#feature scaling is compulsory for training neural networks\n",
    "#ImageDataGenerator is a class, training_data_gen is an object created for that class, flow_from_dataframe is a method of ImageDataGenerator class\n",
    "\n",
    "training_set=train_data_gen.flow_from_dataframe(train_df, \"./dataset/train\", x_col='file_name', y_col='class', target_size=(128,128), class_mode='categorical', batch_size=15)\n",
    "#target_size: It is the final size of images. If the image size is big, it will take long time for training\n",
    "#batch_size: It means how many images we want in each batch. Explanation of what is batch_size is explained in this link: https://stats.stackexchange.com/questions/153531/what-is-batch-size-in-neural-network\n",
    "#class_mode: Since, we have only 2 outcomes i.e, cat or dog, class_mode can be set to either binary or categorical. If more than 2 classes are present, then it should be categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ordinary-needle",
   "metadata": {},
   "source": [
    "Preprocessing the validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "basic-treat",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5000 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "#For validation set, we should not apply any transformations (because while predicting, we won't apply any transformations) but feature scaling should be applied to the pixels because during training, we have used feature scaling\n",
    "validation_data_gen=ImageDataGenerator(\n",
    "    rescale=1./255)\n",
    "\n",
    "validation_set=validation_data_gen.flow_from_dataframe(validation_df, \"./dataset/train\", x_col='file_name', y_col='class', target_size=(128,128), class_mode='categorical', batch_size=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "individual-lambda",
   "metadata": {},
   "source": [
    "# Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "referenced-hours",
   "metadata": {},
   "source": [
    "Initialize the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "behind-cincinnati",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn=tf.keras.models.Sequential()\n",
    "#Sequential class: It groups a linear stack of layers into a tf.keras.Model\n",
    "#Sequential provides training and inference features on this model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "primary-brush",
   "metadata": {},
   "source": [
    "Adding the layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incident-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=[128,128,3]))\n",
    "#filters: Used to mention number of feature detectors we want to use\n",
    "#kernel_size: Used to mention size of the feature detector\n",
    "#activation: As long as we haven't reached the output layer, we need to use rectifier activation function. (ReLU layer)\n",
    "#input_shape: When you add your first convolution layer or a dense layer, we have to specify the input shape of your inputs. As in data preprocessing step, we resized the images to 64*64, so use 64,64,3. (for B&W images, use 64,64,1)\n",
    "\n",
    "cnn.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2))\n",
    "#max pooling is applied\n",
    "\n",
    "cnn.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n",
    "\n",
    "cnn.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(filters=128, kernel_size=3, activation='relu'))\n",
    "\n",
    "cnn.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Dropout(0.25))\n",
    "\n",
    "#Flattening\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "\n",
    "#Full Connection\n",
    "cnn.add(tf.keras.layers.Dense(units=512, activation='relu'))\n",
    "#units: It defines the number of hidden neurons you want to have into this fully connected layer.\n",
    "\n",
    "cnn.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "cnn.add(tf.keras.layers.Dropout(0.5))\n",
    "\n",
    "#Output Layer\n",
    "cnn.add(tf.keras.layers.Dense(units=2, activation='softmax'))\n",
    "#Here, number of units should be 1 if the class_mode is binary.\n",
    "#For binary classification, use sigmoid activation function.\n",
    "#For multi label classification, use softmax activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "continuing-gambling",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 126, 126, 32)      896       \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 126, 126, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 63, 63, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 61, 61, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 61, 61, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 30, 30, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 28, 28, 128)       73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 28, 28, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 14, 14, 128)       0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               12845568  \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 512)               2048      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 1026      \n",
      "=================================================================\n",
      "Total params: 12,942,786\n",
      "Trainable params: 12,941,314\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-bryan",
   "metadata": {},
   "source": [
    "# Training the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handed-mechanism",
   "metadata": {},
   "source": [
    "Compiling the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "convenient-brief",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#Optimizers are Classes or methods used to change the attributes of your machine/deep learning model such as weights and \n",
    "#learning rate in order to reduce the losses. Optimizers help to get results faster. TensorFlow mainly supports 9 optimizer \n",
    "#classes\n",
    "\n",
    "#The Loss Function is one of the important components of Neural Network. Loss is nothing but a prediction error of Neural \n",
    "#Net. And the method to calculate the loss is called Loss Function. Loss is used to calculate the gradients for the neural net. \n",
    "#And gradients are used to update the weights. This is how a Neural Net is trained.\n",
    "\n",
    "#We used categorical_crossentropy as loss function as we have multi-label classification\n",
    "#Use binary_crossentropy as loss function when we have binary classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "copyrighted-money",
   "metadata": {},
   "source": [
    "Defining Callbacks and Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "contemporary-russia",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "earlystop=EarlyStopping(patience=10)\n",
    "learning_rate_reduction=ReduceLROnPlateau(monitor='val_accuracy', patience=2, verbose=1, factor=0.5, min_lr=0.00001)\n",
    "callbacks=[earlystop, learning_rate_reduction]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "veterinary-discretion",
   "metadata": {},
   "source": [
    "Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "literary-factor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1333/1333 [==============================] - 1389s 1s/step - loss: 0.7349 - accuracy: 0.6393 - val_loss: 0.5518 - val_accuracy: 0.7225\n",
      "Epoch 2/10\n",
      "1333/1333 [==============================] - 1515s 1s/step - loss: 0.5501 - accuracy: 0.7269 - val_loss: 0.6554 - val_accuracy: 0.6829\n",
      "Epoch 3/10\n",
      "1333/1333 [==============================] - 1748s 1s/step - loss: 0.4971 - accuracy: 0.7641 - val_loss: 0.4227 - val_accuracy: 0.8070\n",
      "Epoch 4/10\n",
      "1333/1333 [==============================] - 1952s 1s/step - loss: 0.4582 - accuracy: 0.7889 - val_loss: 0.4710 - val_accuracy: 0.7818\n",
      "Epoch 5/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.4333 - accuracy: 0.8006\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "1333/1333 [==============================] - 1645s 1s/step - loss: 0.4333 - accuracy: 0.8006 - val_loss: 0.4583 - val_accuracy: 0.7812\n",
      "Epoch 6/10\n",
      "1333/1333 [==============================] - 1584s 1s/step - loss: 0.3811 - accuracy: 0.8306 - val_loss: 0.3018 - val_accuracy: 0.8811\n",
      "Epoch 7/10\n",
      "1333/1333 [==============================] - 1593s 1s/step - loss: 0.3612 - accuracy: 0.8419 - val_loss: 0.3157 - val_accuracy: 0.8699\n",
      "Epoch 8/10\n",
      "1333/1333 [==============================] - ETA: 0s - loss: 0.3475 - accuracy: 0.8475\n",
      "Epoch 00008: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "1333/1333 [==============================] - 1190s 893ms/step - loss: 0.3475 - accuracy: 0.8475 - val_loss: 0.3081 - val_accuracy: 0.8751\n",
      "Epoch 9/10\n",
      "1333/1333 [==============================] - 1178s 884ms/step - loss: 0.3264 - accuracy: 0.8594 - val_loss: 0.2738 - val_accuracy: 0.8937\n",
      "Epoch 10/10\n",
      "1333/1333 [==============================] - 1166s 875ms/step - loss: 0.3169 - accuracy: 0.8618 - val_loss: 0.2470 - val_accuracy: 0.9037\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2b03a902b50>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x=training_set, validation_data=validation_set, epochs=10, validation_steps=5000//15, steps_per_epoch=20000//15, callbacks=callbacks)\n",
    "#5000 is the validation data set size\n",
    "#20000 is the training data set size\n",
    "#15 is the batch size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stone-tenant",
   "metadata": {},
   "source": [
    "Save the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "outstanding-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.save('pet_classification.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "weighted-avatar",
   "metadata": {},
   "source": [
    "# Prediction for Single Input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "about-there",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cat': 0, 'dog': 1}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "productive-relevance",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It's a Cat!\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "im=Image.open(\"dataset/single_prediction/cat_or_dog_4.jpg\")\n",
    "im=im.resize((128,128))\n",
    "\n",
    "#While preprocessing our training set, we created batches of images with batch_size=32. But, here we are making only single prediction. So, here we need to create batches with batch_size=1. (We should not pass single image directly without forming batches)\n",
    "im=np.expand_dims(im,axis=0)\n",
    "#expand_dims: It expands the shape of an array. It inserts a new axis that will appear at the axis position in the expanded array shape. For more explanation: https://numpy.org/doc/stable/reference/generated/numpy.expand_dims.html\n",
    "\n",
    "im=np.array(im)\n",
    "im=im/255   #we have applied feature scaling here because while training we have done the same\n",
    "\n",
    "#predict method\n",
    "pred=cnn.predict_classes([im])[0]\n",
    "if pred==0:\n",
    "    print(\"It's a Cat!\")\n",
    "elif pred==1:\n",
    "    print(\"It's a Dog!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
